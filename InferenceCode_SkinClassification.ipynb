{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image as kimg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 200, 200, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 32)      25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 50, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 25, 64)        102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 128)       204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 6, 6, 128)         409728    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 1,108,259\n",
      "Trainable params: 1,108,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5,5), padding='same', activation='relu',input_shape=(200, 200, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32, (5,5), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (5,5), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, (5,5), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, (5,5), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(128, (5,5), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f96044b21f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"CNN_equHeat/cp-050.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jhanvipatel/Desktop/python/Skin\n",
      "img: normal/p9.jpg\n",
      "Model Prediction: [[1. 0. 0.]]\n",
      "img: normal/p8.jpg\n",
      "Model Prediction: [[1. 0. 0.]]\n",
      "img: normal/p7.jpg\n",
      "Model Prediction: [[0. 0. 1.]]\n",
      "img: normal/p4.jpg\n",
      "Model Prediction: [[0. 0. 1.]]\n",
      "img: normal/p6.jpg\n",
      "Model Prediction: [[0. 0. 1.]]\n",
      "img: normal/p10.jpg\n",
      "Model Prediction: [[1. 0. 0.]]\n",
      "img: normal/p3.jpg\n",
      "Model Prediction: [[1.1339002e-16 0.0000000e+00 1.0000000e+00]]\n",
      "img: normal/p2.jpg\n",
      "Model Prediction: [[0. 0. 1.]]\n",
      "img: normal/p1.jpg\n",
      "Model Prediction: [[1. 0. 0.]]\n",
      "img: normal/p5.jpg\n",
      "Model Prediction: [[1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "# from pathlib import Path\n",
    "# import glob\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image\n",
    "# count = 0\n",
    "# path=Path('/home/jhanvipatel/Desktop/python/Skin/')\n",
    "# print(path)\n",
    "# images=[]\n",
    "# for img in glob.glob(\"normal/*.jpg\"):\n",
    "#     print(\"img:\",img)\n",
    "#     img = kimg.load_img(img,target_size=(200,200))\n",
    "#     images = kimg.img_to_array(img)\n",
    "#     # expand dimension of image\n",
    "#     gray_img=np.expand_dims(images,axis=0)\n",
    "#     ans = model.predict(gray_img)\n",
    "#     print(\"Model Prediction:\",ans)\n",
    "#     count = count + 1\n",
    "# # print(\"finalcountofimages:\",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jhanvipatel/Desktop/python/Skin\n",
      "enter image path:/home/jhanvipatel/Desktop/python/Skin/p2.jpg\n",
      "Model Prediction: [[0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import cv2\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# def read_this(image_file, gray_scale=False):\n",
    "#     image_src = cv2.imread(image_file)\n",
    "#     if gray_scale:\n",
    "#         image_src = cv2.cvtColor(image_src, cv2.COLOR_BGR2GRAY)\n",
    "#     else:\n",
    "#         image_src = cv2.cvtColor(image_src, cv2.COLOR_BGR2RGB)\n",
    "#     return image_src\n",
    "\n",
    "def enhance_contrast(image_matrix, bins=256):\n",
    "    image_flattened = image_matrix.flatten()\n",
    "    image_hist = np.zeros(bins)\n",
    "\n",
    "    # frequency count of each pixel\n",
    "    for pix in image_matrix:\n",
    "        image_hist[pix] += 1\n",
    "\n",
    "    # cummulative sum\n",
    "    cum_sum = np.cumsum(image_hist)\n",
    "    norm = (cum_sum - cum_sum.min()) * 255\n",
    "    # normalization of the pixel values\n",
    "    n_ = cum_sum.max() - cum_sum.min()\n",
    "    uniform_norm = norm / n_\n",
    "    uniform_norm = uniform_norm.astype(np.uint8)\n",
    "\n",
    "    # flat histogram\n",
    "    image_eq = uniform_norm[image_flattened]\n",
    "    # reshaping the flattened matrix to its original shape\n",
    "    image_eq = np.reshape(a=image_eq, newshape=image_matrix.shape)\n",
    "\n",
    "    return image_eq\n",
    "\n",
    "def equalize_this(image_file, with_plot=False, gray_scale=False, bins=256):\n",
    "#     image_src = read_this(image_file=image_file, gray_scale=gray_scale)\n",
    "    gray_image = cv2.cvtColor(image_file, cv2.COLOR_BGR2GRAY)\n",
    "#     if not gray_scale:\n",
    "#         r_image = image_src[:, :, 0]\n",
    "#         g_image = image_src[:, :, 1]\n",
    "#         b_image = image_src[:, :, 2]\n",
    "\n",
    "#         r_image_eq = enhance_contrast(image_matrix=r_image)\n",
    "#         g_image_eq = enhance_contrast(image_matrix=g_image)\n",
    "#         b_image_eq = enhance_contrast(image_matrix=b_image)\n",
    "\n",
    "#         image_eq = np.dstack(tup=(r_image_eq, g_image_eq, b_image_eq))\n",
    "#         cmap_val = None\n",
    "#         image_eq = image_eq.astype(np.uint8)\n",
    "#         #         cv2.imwrite(img, image_eq)\n",
    "# #         io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
    "\n",
    "#     else:\n",
    "    image_eq = enhance_contrast(image_matrix=gray_image)\n",
    "    cmap_val = 'gray'\n",
    "    #         #cv2.imwrite(img, image_eq)\n",
    "#         io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
    "    return image_eq\n",
    "\n",
    "\n",
    "\n",
    "path=Path('/home/jhanvipatel/Desktop/python/Skin/')\n",
    "print(path)\n",
    "images=[]\n",
    "# for imagepath in glob.glob(\"new_folder/*.jpg\"):\n",
    "#     print(\"img:\",imagepath)\n",
    "#     image = cv2.imread(imagepath,0)\n",
    "#     heatmap2 = cv2.applyColorMap(image, cv2.COLORMAP_HOT)\n",
    "#     print(type(heatmap2))\n",
    "# #     img_resize = cv2.resize(heatmap2,(200,200))\n",
    "# #     print(img_resize.shape)\n",
    "# #     dim = (200, 200)\n",
    " \n",
    "# #     # resize image\n",
    "# #     resized = cv2.resize(heatmap2, dim, interpolation = cv2.INTER_AREA)\n",
    " \n",
    "# #     print('Resized Dimensions : ',resized.shape)\n",
    "#     cv2.imwrite('heatmapimg.jpg',heatmap2)\n",
    "#     equ_img = equalize_this(heatmap2, with_plot=False,gray_scale=True )\n",
    "#     cv2.imwrite('equimg.jpg',equ_img)\n",
    "#     images = kimg.img_to_array(equ_img)\n",
    "#     gray_img=np.expand_dims(images,axis=0)\n",
    "#     ans = model.predict(gray_img)\n",
    "#     ans = np.argmax(ans)\n",
    "#     print(\"Model Prediction:\",ans)\n",
    "    \n",
    "    \n",
    "# for imagepath in glob.glob(\"new_folder/*.jpg\"):\n",
    "#     print(\"img:\",imagepath)\n",
    "#     image = cv2.imread(imagepath, 0)\n",
    "#     heatmap2 = cv2.applyColorMap(image, cv2.COLORMAP_HOT)\n",
    "#     heatmapimg = cv2.imwrite(imagepath, heatmap2)\n",
    "# time.sleep(5)\n",
    "# for img in glob.glob(\"new_folder/*.jpg\"):\n",
    "#     print(\"img_name:\",img)\n",
    "#     imArray = cv2.imread(img)\n",
    "#     equalize_this(image_file=img, with_plot=False,gray_scale=True )\n",
    "\n",
    "# count = 0\n",
    "# for img in glob.glob(\"new_folder/*.jpg\"):\n",
    "#     print(\"img:\",img)\n",
    "#     img = kimg.load_img(img,target_size=(200,200))\n",
    "#     images = kimg.img_to_array(img)\n",
    "#     # expand dimension of image\n",
    "#     gray_img=np.expand_dims(images,axis=0)\n",
    "#     ans = model.predict(gray_img)\n",
    "#     print(\"Model Prediction:\",ans)\n",
    "#     count = count + 1    \n",
    "\n",
    "imagepath = input(\"enter image path:\")\n",
    "image = cv2.imread(imagepath, 0)\n",
    "heatmap2 = cv2.applyColorMap(image, cv2.COLORMAP_HOT)\n",
    "# heatmapimg = cv2.imwrite(imagepath, heatmap2)\n",
    "time.sleep(3)\n",
    "# imArray = cv2.imread(imagepath)\n",
    "equalize_this(image_file=heatmap2, with_plot=False,gray_scale=True )\n",
    "time.sleep(3)\n",
    "img = kimg.load_img(imagepath,target_size=(200,200))\n",
    "images = kimg.img_to_array(img)\n",
    "# expand dimension of image\n",
    "gray_img=np.expand_dims(images,axis=0)\n",
    "ans = model.predict(gray_img)\n",
    "print(\"Model Prediction:\",ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image as kimg\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def model_architecture():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5,5), padding='same', activation='relu',input_shape=(200, 200, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(32, (5,5), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (5,5), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (5,5), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (5,5), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (5,5), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    model.load_weights(\"CNN_equHeat/cp-050.pkl\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "   \n",
    "\n",
    "def mymodel(imagefilename,model):\n",
    "    def read_this(image_file, gray_scale=False):\n",
    "        image_src = cv2.imread(image_file)\n",
    "        if gray_scale:\n",
    "            image_src = cv2.cvtColor(image_src, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            image_src = cv2.cvtColor(image_src, cv2.COLOR_BGR2RGB)\n",
    "        return image_src\n",
    "\n",
    "    def enhance_contrast(image_matrix, bins=256):\n",
    "        image_flattened = image_matrix.flatten()\n",
    "        image_hist = np.zeros(bins)\n",
    "\n",
    "        # frequency count of each pixel\n",
    "        for pix in image_matrix:\n",
    "            image_hist[pix] += 1\n",
    "\n",
    "        # cummulative sum\n",
    "        cum_sum = np.cumsum(image_hist)\n",
    "        norm = (cum_sum - cum_sum.min()) * 255\n",
    "        # normalization of the pixel values\n",
    "        n_ = cum_sum.max() - cum_sum.min()\n",
    "        uniform_norm = norm / n_\n",
    "        uniform_norm = uniform_norm.astype(np.uint8)\n",
    "\n",
    "        # flat histogram\n",
    "        image_eq = uniform_norm[image_flattened]\n",
    "        # reshaping the flattened matrix to its original shape\n",
    "        image_eq = np.reshape(a=image_eq, newshape=image_matrix.shape)\n",
    "\n",
    "        return image_eq\n",
    "\n",
    "    def equalize_this(image_src, with_plot=False, gray_scale=False, bins=256):\n",
    "    #     image_src = read_this(image_file=image_file, gray_scale=gray_scale)\n",
    "        if not gray_scale:\n",
    "            r_image = image_src[:, :, 0]\n",
    "            g_image = image_src[:, :, 1]\n",
    "            b_image = image_src[:, :, 2]\n",
    "\n",
    "            r_image_eq = enhance_contrast(image_matrix=r_image)\n",
    "            g_image_eq = enhance_contrast(image_matrix=g_image)\n",
    "            b_image_eq = enhance_contrast(image_matrix=b_image)\n",
    "\n",
    "            image_eq = np.dstack(tup=(r_image_eq, g_image_eq, b_image_eq))\n",
    "            cmap_val = None\n",
    "            image_eq = image_eq.astype(np.uint8)\n",
    "            #         cv2.imwrite(img, image_eq)\n",
    "            #io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
    "\n",
    "        else:\n",
    "            image_eq = enhance_contrast(image_matrix=image_src)\n",
    "            cmap_val = 'gray'\n",
    "            #         cv2.imwrite(img, image_eq)\n",
    "            #io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
    "        return image_eq\n",
    "    \n",
    "    image = cv2.imread(imagefilename, 0)\n",
    "    heatmap2 = cv2.applyColorMap(image, cv2.COLORMAP_HOT)\n",
    "    equ_img = equalize_this(heatmap2, with_plot=False,gray_scale=True )\n",
    "    equ_img_resize = cv2.resize(equ_img,(200,200))\n",
    "    images = kimg.img_to_array(equ_img_resize)\n",
    "    gray_img=np.expand_dims(images,axis=0)\n",
    "    ans = model.predict(gray_img)\n",
    "    ans = np.argmax(ans)\n",
    "    print(\"Model Prediction:\",ans)\n",
    "    return ans\n",
    "\n",
    "def main(imagefilename):\n",
    "    model = model_architecture()\n",
    "    predictions = mymodel(imagefilename,model)\n",
    "    print(predictions)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prediction: 0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main('p1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_this(image_file, gray_scale=False):\n",
    "    image_src = cv2.imread(image_file)\n",
    "    if gray_scale:\n",
    "        image_src = cv2.cvtColor(image_src, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        image_src = cv2.cvtColor(image_src, cv2.COLOR_BGR2RGB)\n",
    "    return image_src\n",
    "\n",
    "def enhance_contrast(image_matrix, bins=256):\n",
    "    image_flattened = image_matrix.flatten()\n",
    "    image_hist = np.zeros(bins)\n",
    "\n",
    "    # frequency count of each pixel\n",
    "    for pix in image_matrix:\n",
    "        image_hist[pix] += 1\n",
    "\n",
    "    # cummulative sum\n",
    "    cum_sum = np.cumsum(image_hist)\n",
    "    norm = (cum_sum - cum_sum.min()) * 255\n",
    "    # normalization of the pixel values\n",
    "    n_ = cum_sum.max() - cum_sum.min()\n",
    "    uniform_norm = norm / n_\n",
    "    uniform_norm = uniform_norm.astype(np.uint8)\n",
    "\n",
    "    # flat histogram\n",
    "    image_eq = uniform_norm[image_flattened]\n",
    "    # reshaping the flattened matrix to its original shape\n",
    "    image_eq = np.reshape(a=image_eq, newshape=image_matrix.shape)\n",
    "\n",
    "    return image_eq\n",
    "\n",
    "def equalize_this(image_src, with_plot=False, gray_scale=False, bins=256):\n",
    "#     image_src = read_this(image_file=image_file, gray_scale=gray_scale)\n",
    "    if not gray_scale:\n",
    "        r_image = image_src[:, :, 0]\n",
    "        g_image = image_src[:, :, 1]\n",
    "        b_image = image_src[:, :, 2]\n",
    "\n",
    "        r_image_eq = enhance_contrast(image_matrix=r_image)\n",
    "        g_image_eq = enhance_contrast(image_matrix=g_image)\n",
    "        b_image_eq = enhance_contrast(image_matrix=b_image)\n",
    "\n",
    "        image_eq = np.dstack(tup=(r_image_eq, g_image_eq, b_image_eq))\n",
    "        cmap_val = None\n",
    "        image_eq = image_eq.astype(np.uint8)\n",
    "        #         cv2.imwrite(img, image_eq)\n",
    "        #io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
    "\n",
    "    else:\n",
    "        image_eq = enhance_contrast(image_matrix=image_src)\n",
    "        cmap_val = 'gray'\n",
    "        #         cv2.imwrite(img, image_eq)\n",
    "        #io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
    "    return image_eq\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
