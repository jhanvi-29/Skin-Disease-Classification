{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Input Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. RGB to Contrast Stretching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jhanvipatel/Desktop/python/Skin/\n",
      "img: iphone_images/RGB_Contrast/p9.jpg\n",
      "img: iphone_images/RGB_Contrast/p8.jpg\n",
      "img: iphone_images/RGB_Contrast/p7.jpg\n",
      "img: iphone_images/RGB_Contrast/p4.jpg\n",
      "img: iphone_images/RGB_Contrast/p6.jpg\n",
      "img: iphone_images/RGB_Contrast/p10.jpg\n",
      "img: iphone_images/RGB_Contrast/p3.jpg\n",
      "img: iphone_images/RGB_Contrast/p2.jpg\n",
      "img: iphone_images/RGB_Contrast/p1.jpg\n",
      "img: iphone_images/RGB_Contrast/p5.jpg\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def normalizeRed(intensity):\n",
    "    iI      = intensity\n",
    "    minI    = 86\n",
    "    maxI    = 230\n",
    "    minO    = 0\n",
    "    maxO    = 255\n",
    "    iO      = (iI-minI)*(((maxO-minO)/(maxI-minI))+minO)\n",
    "    return iO\n",
    "\n",
    "def normalizeGreen(intensity):\n",
    "    iI      = intensity\n",
    "    minI    = 90\n",
    "    maxI    = 225\n",
    "    minO    = 0\n",
    "    maxO    = 255\n",
    "    iO      = (iI-minI)*(((maxO-minO)/(maxI-minI))+minO)\n",
    "    return iO \n",
    "\n",
    "def normalizeBlue(intensity):\n",
    "    iI      = intensity\n",
    "    minI    = 100\n",
    "    maxI    = 210\n",
    "    minO    = 0\n",
    "    maxO    = 255\n",
    "    iO      = (iI-minI)*(((maxO-minO)/(maxI-minI))+minO)\n",
    "    return iO\n",
    "\n",
    "path = '/home/jhanvipatel/Desktop/python/Skin/'\n",
    "print(path)\n",
    "for img in glob.glob(\"iphone_images/RGB_Contrast/*.jpg\"):\n",
    "    print(\"img:\",img)\n",
    "    count = 0\n",
    "    imageObject     = Image.open(img)\n",
    "    multiBands      = imageObject.split()\n",
    "    # Apply point operations that does contrast stretching on each color band\n",
    "    normalizedRedBand      = multiBands[0].point(normalizeRed)\n",
    "    normalizedGreenBand    = multiBands[1].point(normalizeGreen)\n",
    "    normalizedBlueBand     = multiBands[2].point(normalizeBlue)\n",
    "    # Create a new image from the contrast stretched red, green and blue brands\n",
    "    normalizedImage = Image.merge(\"RGB\", (normalizedRedBand, normalizedGreenBand, normalizedBlueBand))\n",
    "    im1 = normalizedImage.save(path+img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. RGB Images to Contrast Stretching applied Image Equilisation with gray_scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jhanvipatel/Desktop/python/Skin/\n",
      "img: iphone_images/datapipeline/RGB_C_eqgray/p9.jpg\n",
      "img: iphone_images/datapipeline/RGB_C_eqgray/p8.jpg\n",
      "img: iphone_images/datapipeline/RGB_C_eqgray/p7.jpg\n",
      "img: iphone_images/datapipeline/RGB_C_eqgray/p4.jpg\n",
      "img: iphone_images/datapipeline/RGB_C_eqgray/p6.jpg\n",
      "img: iphone_images/datapipeline/RGB_C_eqgray/p10.jpg\n",
      "img: iphone_images/datapipeline/RGB_C_eqgray/p3.jpg\n",
      "img: iphone_images/datapipeline/RGB_C_eqgray/p2.jpg\n",
      "img: iphone_images/datapipeline/RGB_C_eqgray/p1.jpg\n",
      "img: iphone_images/datapipeline/RGB_C_eqgray/p5.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-42f5e712739f>:92: UserWarning: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/RGB_C_eqgray/p9.jpg is a low contrast image\n",
      "  io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
      "Lossy conversion from int64 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "<ipython-input-26-42f5e712739f>:92: UserWarning: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/RGB_C_eqgray/p8.jpg is a low contrast image\n",
      "  io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
      "Lossy conversion from int64 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "<ipython-input-26-42f5e712739f>:92: UserWarning: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/RGB_C_eqgray/p7.jpg is a low contrast image\n",
      "  io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
      "Lossy conversion from int64 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_name: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/RGB_C_eqgray/p9.jpg\n",
      "img_name: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/RGB_C_eqgray/p8.jpg\n",
      "img_name: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/RGB_C_eqgray/p7.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-42f5e712739f>:92: UserWarning: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/RGB_C_eqgray/p4.jpg is a low contrast image\n",
      "  io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
      "Lossy conversion from int64 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "<ipython-input-26-42f5e712739f>:92: UserWarning: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/RGB_C_eqgray/p6.jpg is a low contrast image\n",
      "  io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
      "Lossy conversion from int64 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "<ipython-input-26-42f5e712739f>:92: UserWarning: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/RGB_C_eqgray/p10.jpg is a low contrast image\n",
      "  io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
      "Lossy conversion from int64 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_name: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/RGB_C_eqgray/p4.jpg\n",
      "img_name: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/RGB_C_eqgray/p6.jpg\n",
      "img_name: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/RGB_C_eqgray/p10.jpg\n",
      "img_name: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/RGB_C_eqgray/p3.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-42f5e712739f>:92: UserWarning: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/RGB_C_eqgray/p3.jpg is a low contrast image\n",
      "  io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
      "Lossy conversion from int64 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "<ipython-input-26-42f5e712739f>:92: UserWarning: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/RGB_C_eqgray/p2.jpg is a low contrast image\n",
      "  io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
      "Lossy conversion from int64 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "<ipython-input-26-42f5e712739f>:92: UserWarning: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/RGB_C_eqgray/p1.jpg is a low contrast image\n",
      "  io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
      "Lossy conversion from int64 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "<ipython-input-26-42f5e712739f>:92: UserWarning: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/RGB_C_eqgray/p5.jpg is a low contrast image\n",
      "  io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
      "Lossy conversion from int64 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_name: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/RGB_C_eqgray/p2.jpg\n",
      "img_name: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/RGB_C_eqgray/p1.jpg\n",
      "img_name: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/RGB_C_eqgray/p5.jpg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "import skimage\n",
    "import pywt   \n",
    "import json\n",
    "import time\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from pathlib import Path\n",
    "from keras.preprocessing import image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def normalizeRed(intensity):\n",
    "    iI      = intensity\n",
    "    minI    = 86\n",
    "    maxI    = 230\n",
    "    minO    = 0\n",
    "    maxO    = 255\n",
    "    iO      = (iI-minI)*(((maxO-minO)/(maxI-minI))+minO)\n",
    "    return iO\n",
    "\n",
    "def normalizeGreen(intensity):\n",
    "    iI      = intensity\n",
    "    minI    = 90\n",
    "    maxI    = 225\n",
    "    minO    = 0\n",
    "    maxO    = 255\n",
    "    iO      = (iI-minI)*(((maxO-minO)/(maxI-minI))+minO)\n",
    "    return iO \n",
    "\n",
    "def normalizeBlue(intensity):\n",
    "    iI      = intensity\n",
    "    minI    = 100\n",
    "    maxI    = 210\n",
    "    minO    = 0\n",
    "    maxO    = 255\n",
    "    iO      = (iI-minI)*(((maxO-minO)/(maxI-minI))+minO)\n",
    "    return iO\n",
    "\n",
    "def read_this(image_file, gray_scale=False):\n",
    "    image_src = cv2.imread(image_file)\n",
    "    if gray_scale:\n",
    "        image_src = cv2.cvtColor(image_src, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        image_src = cv2.cvtColor(image_src, cv2.COLOR_BGR2RGB)\n",
    "    return image_src\n",
    "\n",
    "def enhance_contrast(image_matrix, bins=256):\n",
    "    image_flattened = image_matrix.flatten()\n",
    "    image_hist = np.zeros(bins)\n",
    "\n",
    "    # frequency count of each pixel\n",
    "    for pix in image_matrix:\n",
    "        image_hist[pix] += 1\n",
    "\n",
    "    # cummulative sum\n",
    "    cum_sum = np.cumsum(image_hist)\n",
    "    norm = (cum_sum - cum_sum.min()) * 255\n",
    "    # normalization of the pixel values\n",
    "    n_ = cum_sum.max() - cum_sum.min()\n",
    "    uniform_norm = norm / n_\n",
    "    uniform_norm = uniform_norm.astype(np.uint8)\n",
    "\n",
    "    # flat histogram\n",
    "    image_eq = uniform_norm[image_flattened]\n",
    "    # reshaping the flattened matrix to its original shape\n",
    "    image_eq = np.reshape(a=image_eq, newshape=image_matrix.shape)\n",
    "\n",
    "    return image_eq\n",
    "\n",
    "def equalize_this(image_file, with_plot=False, gray_scale=False, bins=256):\n",
    "    image_src = read_this(image_file=image_file, gray_scale=gray_scale)\n",
    "    if not gray_scale:\n",
    "        r_image = image_src[:, :, 0]\n",
    "        g_image = image_src[:, :, 1]\n",
    "        b_image = image_src[:, :, 2]\n",
    "\n",
    "        r_image_eq = enhance_contrast(image_matrix=r_image)\n",
    "        g_image_eq = enhance_contrast(image_matrix=g_image)\n",
    "        b_image_eq = enhance_contrast(image_matrix=b_image)\n",
    "\n",
    "        image_eq = np.dstack(tup=(r_image_eq, g_image_eq, b_image_eq))\n",
    "        cmap_val = None\n",
    "        image_eq = image_eq.astype(np.uint8)\n",
    "#         cv2.imwrite(img, image_eq)\n",
    "        io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
    "\n",
    "    else:\n",
    "        image_eq = enhance_contrast(image_matrix=image_src)\n",
    "        cmap_val = 'gray'\n",
    "        #         cv2.imwrite(img, image_eq)\n",
    "        io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
    "    return image_eq\n",
    "\n",
    "        \n",
    "path = '/home/jhanvipatel/Desktop/python/Skin/'\n",
    "print(path)\n",
    "for img in glob.glob(\"iphone_images/datapipeline/RGB_C_eqgray/*.jpg\"):\n",
    "    print(\"img:\",img)\n",
    "    count = 0\n",
    "    imageObject     = Image.open(img)\n",
    "    multiBands      = imageObject.split()\n",
    "    # Apply point operations that does contrast stretching on each color band\n",
    "    normalizedRedBand      = multiBands[0].point(normalizeRed)\n",
    "    normalizedGreenBand    = multiBands[1].point(normalizeGreen)\n",
    "    normalizedBlueBand     = multiBands[2].point(normalizeBlue)\n",
    "    # Create a new image from the contrast stretched red, green and blue brands\n",
    "    normalizedImage = Image.merge(\"RGB\", (normalizedRedBand, normalizedGreenBand, normalizedBlueBand))\n",
    "    im1 = normalizedImage.save(path+img)\n",
    "time.sleep(5)\n",
    "images=[]\n",
    "\n",
    "for img in glob.glob(\"iphone_images/datapipeline/RGB_C_eqgray/*.jpg\"):\n",
    "        print(\"img_name:\",img)\n",
    "        imArray = cv2.imread(img)\n",
    "        equalize_this(image_file=img, with_plot=False,gray_scale=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. RGB Images to Heatmap applied Image Equilisation with gray_scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jhanvipatel/Desktop/python/Skin\n",
      "img: iphone_images/datapipeline/RGB_h_eqgrey/p9.jpg\n",
      "img: iphone_images/datapipeline/RGB_h_eqgrey/p8.jpg\n",
      "img: iphone_images/datapipeline/RGB_h_eqgrey/p7.jpg\n",
      "img: iphone_images/datapipeline/RGB_h_eqgrey/p4.jpg\n",
      "img: iphone_images/datapipeline/RGB_h_eqgrey/p6.jpg\n",
      "img: iphone_images/datapipeline/RGB_h_eqgrey/p10.jpg\n",
      "img: iphone_images/datapipeline/RGB_h_eqgrey/p3.jpg\n",
      "img: iphone_images/datapipeline/RGB_h_eqgrey/p2.jpg\n",
      "img: iphone_images/datapipeline/RGB_h_eqgrey/p1.jpg\n",
      "img: iphone_images/datapipeline/RGB_h_eqgrey/p5.jpg\n",
      "img_name: iphone_images/datapipeline/RGB_h_eqgrey/p9.jpg\n",
      "img_name: iphone_images/datapipeline/RGB_h_eqgrey/p8.jpg\n",
      "img_name: iphone_images/datapipeline/RGB_h_eqgrey/p7.jpg\n",
      "img_name: iphone_images/datapipeline/RGB_h_eqgrey/p4.jpg\n",
      "img_name: iphone_images/datapipeline/RGB_h_eqgrey/p6.jpg\n",
      "img_name: iphone_images/datapipeline/RGB_h_eqgrey/p10.jpg\n",
      "img_name: iphone_images/datapipeline/RGB_h_eqgrey/p3.jpg\n",
      "img_name: iphone_images/datapipeline/RGB_h_eqgrey/p2.jpg\n",
      "img_name: iphone_images/datapipeline/RGB_h_eqgrey/p1.jpg\n",
      "img_name: iphone_images/datapipeline/RGB_h_eqgrey/p5.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "count = 1\n",
    "def read_this(image_file, gray_scale=False):\n",
    "    image_src = cv2.imread(image_file)\n",
    "    if gray_scale:\n",
    "        image_src = cv2.cvtColor(image_src, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        image_src = cv2.cvtColor(image_src, cv2.COLOR_BGR2RGB)\n",
    "    return image_src\n",
    "\n",
    "def enhance_contrast(image_matrix, bins=256):\n",
    "    image_flattened = image_matrix.flatten()\n",
    "    image_hist = np.zeros(bins)\n",
    "\n",
    "    # frequency count of each pixel\n",
    "    for pix in image_matrix:\n",
    "        image_hist[pix] += 1\n",
    "\n",
    "    # cummulative sum\n",
    "    cum_sum = np.cumsum(image_hist)\n",
    "    norm = (cum_sum - cum_sum.min()) * 255\n",
    "    # normalization of the pixel values\n",
    "    n_ = cum_sum.max() - cum_sum.min()\n",
    "    uniform_norm = norm / n_\n",
    "    uniform_norm = uniform_norm.astype(np.uint8)\n",
    "\n",
    "    # flat histogram\n",
    "    image_eq = uniform_norm[image_flattened]\n",
    "    # reshaping the flattened matrix to its original shape\n",
    "    image_eq = np.reshape(a=image_eq, newshape=image_matrix.shape)\n",
    "\n",
    "    return image_eq\n",
    "\n",
    "def equalize_this(image_file, with_plot=False, gray_scale=False, bins=256):\n",
    "    image_src = read_this(image_file=image_file, gray_scale=gray_scale)\n",
    "    if not gray_scale:\n",
    "        r_image = image_src[:, :, 0]\n",
    "        g_image = image_src[:, :, 1]\n",
    "        b_image = image_src[:, :, 2]\n",
    "\n",
    "        r_image_eq = enhance_contrast(image_matrix=r_image)\n",
    "        g_image_eq = enhance_contrast(image_matrix=g_image)\n",
    "        b_image_eq = enhance_contrast(image_matrix=b_image)\n",
    "\n",
    "        image_eq = np.dstack(tup=(r_image_eq, g_image_eq, b_image_eq))\n",
    "        cmap_val = None\n",
    "        image_eq = image_eq.astype(np.uint8)\n",
    "        #         cv2.imwrite(img, image_eq)\n",
    "        io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
    "\n",
    "    else:\n",
    "        image_eq = enhance_contrast(image_matrix=image_src)\n",
    "        cmap_val = 'gray'\n",
    "        #         cv2.imwrite(img, image_eq)\n",
    "        io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
    "    return image_eq\n",
    "\n",
    "path=Path('/home/jhanvipatel/Desktop/python/Skin/')\n",
    "print(path)\n",
    "images=[]\n",
    "for imagepath in glob.glob(\"iphone_images/datapipeline/RGB_h_eqgrey/*.jpg\"):\n",
    "    print(\"img:\",imagepath)\n",
    "    image = cv2.imread(imagepath, 0)\n",
    "    heatmap2 = cv2.applyColorMap(image, cv2.COLORMAP_HOT)\n",
    "    heatmapimg = cv2.imwrite(imagepath, heatmap2)\n",
    "time.sleep(5)\n",
    "for img in glob.glob(\"iphone_images/datapipeline/RGB_h_eqgrey/*.jpg\"):\n",
    "        print(\"img_name:\",img)\n",
    "        imArray = cv2.imread(img)\n",
    "        equalize_this(image_file=img, with_plot=False,gray_scale=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. RGB to Heatmap applied Image Equilisation and then image sharpening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here Image Sharpening is Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jhanvipatel/Desktop/python/Skin\n",
      "img: iphone_images/datapipeline/RGB_H_eq_Sh/p9.jpg\n",
      "img: iphone_images/datapipeline/RGB_H_eq_Sh/p6.jpg\n",
      "img_name: iphone_images/datapipeline/RGB_H_eq_Sh/p9.jpg\n",
      "img_name: iphone_images/datapipeline/RGB_H_eq_Sh/p6.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "from PIL import ImageFilter\n",
    "count = 1\n",
    "def read_this(image_file, gray_scale=False):\n",
    "    image_src = cv2.imread(image_file)\n",
    "    if gray_scale:\n",
    "        image_src = cv2.cvtColor(image_src, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        image_src = cv2.cvtColor(image_src, cv2.COLOR_BGR2RGB)\n",
    "    return image_src\n",
    "\n",
    "def enhance_contrast(image_matrix, bins=256):\n",
    "    image_flattened = image_matrix.flatten()\n",
    "    image_hist = np.zeros(bins)\n",
    "\n",
    "    # frequency count of each pixel\n",
    "    for pix in image_matrix:\n",
    "        image_hist[pix] += 1\n",
    "\n",
    "    # cummulative sum\n",
    "    cum_sum = np.cumsum(image_hist)\n",
    "    norm = (cum_sum - cum_sum.min()) * 255\n",
    "    # normalization of the pixel values\n",
    "    n_ = cum_sum.max() - cum_sum.min()\n",
    "    uniform_norm = norm / n_\n",
    "    uniform_norm = uniform_norm.astype(np.uint8)\n",
    "\n",
    "    # flat histogram\n",
    "    image_eq = uniform_norm[image_flattened]\n",
    "    # reshaping the flattened matrix to its original shape\n",
    "    image_eq = np.reshape(a=image_eq, newshape=image_matrix.shape)\n",
    "\n",
    "    return image_eq\n",
    "\n",
    "def equalize_this(image_file, with_plot=False, gray_scale=False, bins=256):\n",
    "    image_src = read_this(image_file=image_file, gray_scale=gray_scale)\n",
    "    if not gray_scale:\n",
    "        r_image = image_src[:, :, 0]\n",
    "        g_image = image_src[:, :, 1]\n",
    "        b_image = image_src[:, :, 2]\n",
    "\n",
    "        r_image_eq = enhance_contrast(image_matrix=r_image)\n",
    "        g_image_eq = enhance_contrast(image_matrix=g_image)\n",
    "        b_image_eq = enhance_contrast(image_matrix=b_image)\n",
    "\n",
    "        image_eq = np.dstack(tup=(r_image_eq, g_image_eq, b_image_eq))\n",
    "        cmap_val = None\n",
    "        image_eq = image_eq.astype(np.uint8)\n",
    "        #         cv2.imwrite(img, image_eq)\n",
    "        io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
    "\n",
    "    else:\n",
    "        image_eq = enhance_contrast(image_matrix=image_src)\n",
    "        cmap_val = 'gray'\n",
    "        #         cv2.imwrite(img, image_eq)\n",
    "        io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
    "    return image_eq\n",
    "\n",
    "path=Path('/home/jhanvipatel/Desktop/python/Skin/')\n",
    "print(path)\n",
    "images=[]\n",
    "for imagepath in glob.glob(\"iphone_images/datapipeline/RGB_H_eq_Sh/*.jpg\"):\n",
    "    print(\"img:\",imagepath)\n",
    "    image = cv2.imread(imagepath, 0)\n",
    "    heatmap2 = cv2.applyColorMap(image, cv2.COLORMAP_HOT)\n",
    "    heatmapimg = cv2.imwrite(imagepath, heatmap2)\n",
    "time.sleep(5)\n",
    "for img in glob.glob(\"iphone_images/datapipeline/RGB_H_eq_Sh/*.jpg\"):\n",
    "        print(\"img_name:\",img)\n",
    "        imArray = cv2.imread(img)\n",
    "        equalize_this(image_file=img, with_plot=False,gray_scale=True)\n",
    "        imageName = Image.open(img);\n",
    "        sharpened2 = imageName.filter(ImageFilter.SHARPEN);\n",
    "        sharpened2 = sharpened2.save(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. RGB Images converted to Image Sharpening and processed Equilisation on it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_name: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/rgb_shrp_eq/sep5.jpg\n",
      "img_name: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/rgb_shrp_eq/sep7.jpg\n",
      "img_name: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/rgb_shrp_eq/sep2.jpg\n",
      "img_name: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/rgb_shrp_eq/sep3.jpg\n",
      "img_name: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/rgb_shrp_eq/sep9.jpg\n",
      "img_name: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/rgb_shrp_eq/sep10.jpg\n",
      "img_name: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/rgb_shrp_eq/sep4.jpg\n",
      "img_name: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/rgb_shrp_eq/sep8.jpg\n",
      "img_name: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/rgb_shrp_eq/sep1.jpg\n",
      "img_name: /home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/rgb_shrp_eq/sep6.jpg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import skimage\n",
    "import pywt   \n",
    "from pathlib import Path\n",
    "import glob\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import io\n",
    "from PIL import Image, ImageOps\n",
    "from PIL import ImageFilter\n",
    "\n",
    "\n",
    "def read_this(image_file, gray_scale=False):\n",
    "    image_src = cv2.imread(image_file)\n",
    "    if gray_scale:\n",
    "        image_src = cv2.cvtColor(image_src, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        image_src = cv2.cvtColor(image_src, cv2.COLOR_BGR2RGB)\n",
    "    return image_src\n",
    "\n",
    "def enhance_contrast(image_matrix, bins=256):\n",
    "    image_flattened = image_matrix.flatten()\n",
    "    image_hist = np.zeros(bins)\n",
    "\n",
    "    # frequency count of each pixel\n",
    "    for pix in image_matrix:\n",
    "        image_hist[pix] += 1\n",
    "\n",
    "    # cummulative sum\n",
    "    cum_sum = np.cumsum(image_hist)\n",
    "    norm = (cum_sum - cum_sum.min()) * 255\n",
    "    # normalization of the pixel values\n",
    "    n_ = cum_sum.max() - cum_sum.min()\n",
    "    uniform_norm = norm / n_\n",
    "    uniform_norm = uniform_norm.astype('int')\n",
    "\n",
    "    # flat histogram\n",
    "    image_eq = uniform_norm[image_flattened]\n",
    "    # reshaping the flattened matrix to its original shape\n",
    "    image_eq = np.reshape(a=image_eq, newshape=image_matrix.shape)\n",
    "\n",
    "    return image_eq\n",
    "\n",
    "def equalize_this(image_file, with_plot=False, gray_scale=False, bins=256):\n",
    "    image_src = read_this(image_file=image_file, gray_scale=gray_scale)\n",
    "    if not gray_scale:\n",
    "        r_image = image_src[:, :, 0]\n",
    "        g_image = image_src[:, :, 1]\n",
    "        b_image = image_src[:, :, 2]\n",
    "\n",
    "        r_image_eq = enhance_contrast(image_matrix=r_image)\n",
    "        g_image_eq = enhance_contrast(image_matrix=g_image)\n",
    "        b_image_eq = enhance_contrast(image_matrix=b_image)\n",
    "\n",
    "        image_eq = np.dstack(tup=(r_image_eq, g_image_eq, b_image_eq))\n",
    "        cmap_val = None\n",
    "        image_eq = image_eq.astype(np.uint8)\n",
    "        #         cv2.imwrite(img, image_eq)\n",
    "        io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
    "\n",
    "    else:\n",
    "        image_eq = enhance_contrast(image_matrix=image_src)\n",
    "        cmap_val = 'gray'\n",
    "        #         cv2.imwrite(img, image_eq)\n",
    "        io.imsave(img, image_eq)             #save the equilised image by replacing the original image.\n",
    "    return image_eq\n",
    "\n",
    "images=[]\n",
    "\n",
    "for img in glob.glob(\"/home/jhanvipatel/Desktop/python/Skin/iphone_images/datapipeline/rgb_shrp_eq/*.jpg\"):\n",
    "        print(\"img_name:\",img)\n",
    "        imageName = Image.open(img);\n",
    "        sharpened2 = imageName.filter(ImageFilter.SHARPEN);\n",
    "        sharpened2 = sharpened2.save(img)   \n",
    "        imArray = cv2.imread(img)\n",
    "        equalize_this(image_file=img, with_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
